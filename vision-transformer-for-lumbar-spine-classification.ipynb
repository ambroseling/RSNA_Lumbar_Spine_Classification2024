{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":4534,"sourceType":"modelInstanceVersion","modelInstanceId":3326}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## RSNA 2024 Lumbar Spine Degenerative Classification\n- In this task, we are going to try to classify Lumbar Spines.\n- To do this instead of building models, we will use pre-trained models built with ViT.\n- Here are the steps\n1.  imports\n2.  read data\n3.  convert data to dataset\n4.  import model\n5.  prepare data, transform data and model args\n6.  train\n","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:36.480791Z","iopub.execute_input":"2024-07-06T14:02:36.481054Z","iopub.status.idle":"2024-07-06T14:02:50.721625Z","shell.execute_reply.started":"2024-07-06T14:02:36.481029Z","shell.execute_reply":"2024-07-06T14:02:50.720493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, gc, sys, copy, pickle\nfrom pathlib import Path\nimport glob\nfrom tqdm.auto import tqdm\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pydicom\nfrom PIL import Image as PILImage\nfrom datasets import Dataset, Image,Features\nimport warnings\nimport torch\nwarnings.filterwarnings(\"ignore\")\ntqdm.pandas()\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-06T14:02:50.723838Z","iopub.execute_input":"2024-07-06T14:02:50.724138Z","iopub.status.idle":"2024-07-06T14:02:55.695301Z","shell.execute_reply.started":"2024-07-06T14:02:50.72411Z","shell.execute_reply":"2024-07-06T14:02:55.694469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    torch.manual_seed(SEED)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(SEED)\n        torch.cuda.manual_seed_all(SEED)\n        torch.backends.cudnn.deterministic = False\n        torch.backends.cudnn.benchmark = True\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n#     tf.random.set_seed(SEED)\n#     keras.utils.set_random_seed(seed=SEED)\n    print('seeding done!!!')\n\ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:55.696249Z","iopub.execute_input":"2024-07-06T14:02:55.696667Z","iopub.status.idle":"2024-07-06T14:02:55.704271Z","shell.execute_reply.started":"2024-07-06T14:02:55.696641Z","shell.execute_reply":"2024-07-06T14:02:55.703342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\ndf_train_desc = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\ndf_train_desc['image_path'] = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/\" + df_train_desc['study_id'].astype(str) +\"/\"+ df_train_desc['series_id'].astype(str) + \"/\"+ df_train_desc['instance_number'].astype(str) + \".dcm\"\ndf_train_desc.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:55.705503Z","iopub.execute_input":"2024-07-06T14:02:55.705793Z","iopub.status.idle":"2024-07-06T14:02:56.032206Z","shell.execute_reply.started":"2024-07-06T14:02:55.705769Z","shell.execute_reply":"2024-07-06T14:02:56.031358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_melted = df_train.melt(id_vars=['study_id'], var_name='condition_level', value_name='value')\n\n# Split the 'condition_level' column to extract 'condition' and 'level'\ndf_train_melted[['conditions', 'level']] = df_train_melted['condition_level'].str.rsplit('_', n=2, expand=True).iloc[:, 1:]\ndf_train_melted['condition'] = df_train_melted['condition_level'].apply(lambda x: '_'.join(x.split('_')[:-2])).str.replace(\"_\",\" \").str.title()\ndf_train_melted['level'] = df_train_melted['conditions'].str.upper() +\"/\"+ df_train_melted['level'].str.upper()\n# Remove the original 'condition_level' column\ndf_train_melted = df_train_melted.drop(columns=['condition_level', 'conditions'])\n\n# Rename columns for clarity\ndf_train_melted = df_train_melted.rename(columns={'value': 'severity'})\ndf_train_melted.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.035354Z","iopub.execute_input":"2024-07-06T14:02:56.035779Z","iopub.status.idle":"2024-07-06T14:02:56.285269Z","shell.execute_reply.started":"2024-07-06T14:02:56.035751Z","shell.execute_reply":"2024-07-06T14:02:56.284327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = df_train_desc.merge(df_train_melted, on = [\"study_id\",\"level\",\"condition\"],how = \"left\")\ndf_final","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.286268Z","iopub.execute_input":"2024-07-06T14:02:56.28653Z","iopub.status.idle":"2024-07-06T14:02:56.361648Z","shell.execute_reply.started":"2024-07-06T14:02:56.286508Z","shell.execute_reply":"2024-07-06T14:02:56.36078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.362977Z","iopub.execute_input":"2024-07-06T14:02:56.363358Z","iopub.status.idle":"2024-07-06T14:02:56.4017Z","shell.execute_reply.started":"2024-07-06T14:02:56.363325Z","shell.execute_reply":"2024-07-06T14:02:56.400853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dicom_image(file_path, target_shape=(224, 224)):\n    dicom = pydicom.dcmread(file_path)\n    # Convert the DICOM pixel data to a NumPy array\n    image = dicom.pixel_array\n    # Normalize pixel values (if necessary)\n    image = (image / np.max(image) * 255).astype(np.uint8)\n    # Convert NumPy array to PIL Image\n    pil_image = PILImage.fromarray(image)\n    # Resize image to the target shape\n    resized_image = pil_image.resize(target_shape)\n    return resized_image","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.402939Z","iopub.execute_input":"2024-07-06T14:02:56.403588Z","iopub.status.idle":"2024-07-06T14:02:56.408972Z","shell.execute_reply.started":"2024-07-06T14:02:56.403554Z","shell.execute_reply":"2024-07-06T14:02:56.408039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.dropna(subset=['image_path', 'severity'], inplace=True)\nimage_paths = df_final['image_path'].values\nlabels = df_final['severity'].values\ndataset = Dataset.from_dict({\"image_path\": image_paths, \"label\": labels})","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.410088Z","iopub.execute_input":"2024-07-06T14:02:56.410375Z","iopub.status.idle":"2024-07-06T14:02:56.501532Z","shell.execute_reply.started":"2024-07-06T14:02:56.410341Z","shell.execute_reply":"2024-07-06T14:02:56.500663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_list = list(set(labels))\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels_list):\n    label2id[label] = i\n    id2label[i] = label\nprint(id2label, '\\n\\n', label2id)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.50258Z","iopub.execute_input":"2024-07-06T14:02:56.502856Z","iopub.status.idle":"2024-07-06T14:02:56.511123Z","shell.execute_reply.started":"2024-07-06T14:02:56.502832Z","shell.execute_reply":"2024-07-06T14:02:56.510226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.512196Z","iopub.execute_input":"2024-07-06T14:02:56.512889Z","iopub.status.idle":"2024-07-06T14:02:56.522148Z","shell.execute_reply.started":"2024-07-06T14:02:56.512857Z","shell.execute_reply":"2024-07-06T14:02:56.521244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def converts(example):\n    example['image'] = read_dicom_image(example['image_path'], target_shape=(224, 224))\n    return example\ndataset = dataset.map(converts)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:02:56.523444Z","iopub.execute_input":"2024-07-06T14:02:56.523822Z","iopub.status.idle":"2024-07-06T14:29:13.391616Z","shell.execute_reply.started":"2024-07-06T14:02:56.523791Z","shell.execute_reply":"2024-07-06T14:29:13.390686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_images(dataset, num_rows=2, num_columns=5, figsize=(12, 10), max_title_length=30):\n    total_images = num_rows * num_columns\n\n    # Shuffle the dataset to get a random selection of images\n    indices = list(range(len(dataset)))\n    random.shuffle(indices)\n    \n    fig, axes = plt.subplots(num_rows, num_columns, figsize=figsize)\n\n    for i, idx in enumerate(indices):\n        if i >= total_images:\n            break\n        example = dataset[idx]\n        \n        row = i // num_columns\n        col = i % num_columns\n\n        image = example[\"image\"]\n        label = example[\"label\"]  \n\n        # Display image\n        axes[row, col].imshow(image)\n        axes[row, col].axis('off')\n\n        axes[row, col].set_title(label, wrap=True, fontsize='small')\n    # Adjust spacing and layout\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\ndisplay_images(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:13.392919Z","iopub.execute_input":"2024-07-06T14:29:13.393759Z","iopub.status.idle":"2024-07-06T14:29:14.666249Z","shell.execute_reply.started":"2024-07-06T14:29:13.393719Z","shell.execute_reply":"2024-07-06T14:29:14.665338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training with Beit","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import (accuracy_score,\n                             roc_auc_score,\n                             precision_score,\n                             recall_score,\n                             confusion_matrix,\n                             classification_report,\n                             f1_score)\n\nfrom transformers import (TrainingArguments,\n                          Trainer,\n                          DefaultDataCollator)\nfrom transformers import (BeitImageProcessor,\n                          BeitForImageClassification,\n                          ViTImageProcessor, \n                          ViTForImageClassification,\n                          AutoImageProcessor, \n                          AutoModel)\nimport evaluate\nimport torch\nfrom torchvision import transforms\nfrom torchvision.transforms import (CenterCrop,\n                                    Compose,\n                                    Normalize,\n                                    RandomRotation,\n                                    RandomResizedCrop,\n                                    RandomHorizontalFlip,\n                                    RandomAdjustSharpness,\n                                    Resize,\n                                    ToTensor)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:14.670445Z","iopub.execute_input":"2024-07-06T14:29:14.670734Z","iopub.status.idle":"2024-07-06T14:29:28.063011Z","shell.execute_reply.started":"2024-07-06T14:29:14.670709Z","shell.execute_reply":"2024-07-06T14:29:28.062031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_path = \"/kaggle/working/beit-base\"\nprocessor = BeitImageProcessor.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k')\n#processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n#processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\n\nsize = processor.size[\"height\"]\nimage_mean, image_std = processor.image_mean, processor.image_std\nnormalize = transforms.Normalize(mean=image_mean, std=image_std)\n\n_train_transforms = transforms.Compose(\n        [\n            transforms.Resize((size, size)),\n            transforms.RandomRotation(15),\n            transforms.RandomAdjustSharpness(2),\n            transforms.ToTensor(),\n            normalize,\n        ]\n    )\n\n\n\n_val_transforms = transforms.Compose(\n        [\n            transforms.Resize((size, size)),\n            transforms.ToTensor(),\n            normalize,\n        ]\n    )\n\ndef train_transforms(examples):\n    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples\n\ndef val_transforms(examples):\n    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:28.064262Z","iopub.execute_input":"2024-07-06T14:29:28.064885Z","iopub.status.idle":"2024-07-06T14:29:28.365738Z","shell.execute_reply.started":"2024-07-06T14:29:28.064857Z","shell.execute_reply":"2024-07-06T14:29:28.364881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.2)\ntrain_data = dataset['train']\ntest_data = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:28.366972Z","iopub.execute_input":"2024-07-06T14:29:28.367255Z","iopub.status.idle":"2024-07-06T14:29:28.399917Z","shell.execute_reply.started":"2024-07-06T14:29:28.36723Z","shell.execute_reply":"2024-07-06T14:29:28.399081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the transforms\ntrain_data.set_transform(train_transforms)\ntest_data.set_transform(val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:28.400932Z","iopub.execute_input":"2024-07-06T14:29:28.401169Z","iopub.status.idle":"2024-07-06T14:29:28.413303Z","shell.execute_reply.started":"2024-07-06T14:29:28.401148Z","shell.execute_reply":"2024-07-06T14:29:28.412333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(examples):\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    labels = torch.tensor([label2id[example[\"label\"]] for example in examples])\n    return {\"pixel_values\": pixel_values, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:28.414459Z","iopub.execute_input":"2024-07-06T14:29:28.414791Z","iopub.status.idle":"2024-07-06T14:29:28.420966Z","shell.execute_reply.started":"2024-07-06T14:29:28.414748Z","shell.execute_reply":"2024-07-06T14:29:28.420138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", num_labels=3,ignore_mismatched_sizes=True)\nmodel = BeitForImageClassification.from_pretrained('microsoft/beit-base-patch16-224-pt22k-ft22k',num_labels=3, ignore_mismatched_sizes=True)\n#model = BeitForImageClassification.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:28.421903Z","iopub.execute_input":"2024-07-06T14:29:28.42222Z","iopub.status.idle":"2024-07-06T14:29:36.224549Z","shell.execute_reply.started":"2024-07-06T14:29:28.422195Z","shell.execute_reply":"2024-07-06T14:29:36.223615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\ndef compute_metricss(eval_pred):\n    predictions = eval_pred.predictions\n    # predictions = np.exp(predictions)/np.exp(predictions).sum(axis=1, keepdims=True)\n    label_ids = eval_pred.label_ids\n    # Calculate accuracy using the loaded accuracy metric\n    acc_score = accuracy.compute(predictions=predictions.argmax(axis=1), references=label_ids)['accuracy']\n    return {\n        \"accuracy\": acc_score\n    }\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return dict(accuracy=accuracy_score(predictions, labels))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:36.225862Z","iopub.execute_input":"2024-07-06T14:29:36.226614Z","iopub.status.idle":"2024-07-06T14:29:36.794005Z","shell.execute_reply.started":"2024-07-06T14:29:36.226578Z","shell.execute_reply":"2024-07-06T14:29:36.793314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric_name = \"accuracy\"\nmodel_name = \"Lumbar Spine Degenerative Classification\"\nnum_train_epochs=1\nargs = TrainingArguments(\n    output_dir=model_name,\n    report_to=None,\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=16,#32\n    per_device_eval_batch_size=8,\n    num_train_epochs=num_train_epochs,\n    weight_decay=0.02,\n    warmup_steps=50,\n    remove_unused_columns=False,\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    save_total_limit=1, # save fewer checkpoints to limit used space\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:36.794937Z","iopub.execute_input":"2024-07-06T14:29:36.795215Z","iopub.status.idle":"2024-07-06T14:29:36.910843Z","shell.execute_reply.started":"2024-07-06T14:29:36.795191Z","shell.execute_reply":"2024-07-06T14:29:36.910112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:36.911967Z","iopub.execute_input":"2024-07-06T14:29:36.91251Z","iopub.status.idle":"2024-07-06T14:29:37.181886Z","shell.execute_reply.started":"2024-07-06T14:29:36.912473Z","shell.execute_reply":"2024-07-06T14:29:37.18091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save_pretrained(\"/kaggle/working/beit-base\", from_pt=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:37.183179Z","iopub.execute_input":"2024-07-06T14:29:37.183848Z","iopub.status.idle":"2024-07-06T14:29:37.188056Z","shell.execute_reply.started":"2024-07-06T14:29:37.183811Z","shell.execute_reply":"2024-07-06T14:29:37.187021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()\ntrainer.train()\n#Training Loss\tValidation Loss\tAccuracy\n#0.430600\t0.445599\t0.815351","metadata":{"execution":{"iopub.status.busy":"2024-07-06T14:29:37.189341Z","iopub.execute_input":"2024-07-06T14:29:37.189935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = trainer.predict(test_data)\noutputs.metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = outputs.label_ids\ny_pred = outputs.predictions.argmax(1)\naccuracy = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='macro')\n\n# Display accuracy and F1 score\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n# Get the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.concatenate(outputs.predictions, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare test dataset","metadata":{}},{"cell_type":"code","source":"# Function to load test images from the nested directory structure\ndef load_test_images(test_images_dir):\n    image_paths = []\n    for root, _, files in os.walk(test_images_dir):\n        for file in files:\n            if file.endswith(\".dcm\"):\n                image_paths.append(os.path.join(root, file))\n    return image_paths\n\n# Directory containing test images\ntest_images_dir = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/\"\ntest_image_paths = load_test_images(test_images_dir)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\ndf_test['image_path'] = test_images_dir + df_test['study_id'].astype(str) +\"/\"+ df_test['series_id'].astype(str) \ndff =pd.DataFrame(test_image_paths)\ndff.columns = ['image_path']\ndff['instance_number'] = dff['image_path'].str.extract(r'/([^/]+)\\.dcm$')\ndff['image_path'] = dff['image_path'].str.replace(r'/([^/]+)\\.dcm$', '', regex=True)\ndf_test_f = dff.merge(df_test, on = 'image_path', how = 'left')\ndf_test_f['image_path'] = df_test_f['image_path'] + \"/\" + df_test_f['instance_number'] +\".dcm\"\ndf_test_f['label']=random.choices(list(label2id.keys()), k=len(df_test_f))\ndf_test_f.drop(['instance_number', 'study_id', 'series_id','series_description'], axis=1, inplace=True)\ndf_test_f","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = Dataset.from_pandas(df_test_f)\ndataset_test = dataset_test.map(converts)\ndataset_test.set_transform(val_transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test[32][\"image\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#outputs = trainer.predict(dataset_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_true = outputs.label_ids\n#y_pred = outputs.predictions.argmax(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"helpers:\n\nhttps://kaggle.com/code/samu2505/rsna-pytorch-train-lb-0-84-cv-0-54\nhttps://www.kaggle.com/code/dima806/sea-animals-image-detection-vit","metadata":{}}]}